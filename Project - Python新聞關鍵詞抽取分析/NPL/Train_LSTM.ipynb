{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\MLenv\\lib\\site-packages\\smart_open\\ssh.py:34: UserWarning: paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
      "  warnings.warn('paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress')\n",
      "D:\\Anaconda\\envs\\MLenv\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 載入正則表達式模塊\n",
    "import re\n",
    "\n",
    "# 載入結巴分詞(簡體)模塊\n",
    "import jieba\n",
    "\n",
    "# 載入語義主題處理模塊\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# 載入 keras 模塊\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# 載入轉簡轉換模塊\n",
    "from zhconv import convert\n",
    "\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pre-trained Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vector_filepahth = 'sgns.wiki.word'\n",
    "cn_model = KeyedVectors.load_word2vec_format(word_vector_filepahth, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pre-trained word vectors: 352217\n"
     ]
    }
   ],
   "source": [
    "print (\"Number of pre-trained word vectors: {:d}\".format(len(cn_model.wv.vocab.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read training data from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 4000 comments from files.\n"
     ]
    }
   ],
   "source": [
    "dataset = 'Hotel_Comment_CN'\n",
    "\n",
    "train_texts_orig = []\n",
    "\n",
    "pos_filename_list = os.listdir(dataset+'/pos')\n",
    "neg_filename_list = os.listdir(dataset+'/neg')\n",
    "\n",
    "# 讀取正面評論 \n",
    "for pos_filename in pos_filename_list:\n",
    "    with open(dataset + '/pos/'+ pos_filename,encoding= 'gbk', errors='ignore') as f:\n",
    "        text = f.read()\n",
    "        train_texts_orig.append(text)\n",
    "        f.close()\n",
    "        \n",
    "# 讀取負面評論        \n",
    "for neg_filename in neg_filename_list:\n",
    "    with open(dataset + '/neg/'+ neg_filename,encoding= 'gbk', errors='ignore') as f:\n",
    "        text = f.read()\n",
    "        train_texts_orig.append(text)\n",
    "        f.close()\n",
    "        \n",
    "        \n",
    "print (\"Read {:d} comments from files.\".format(len(train_texts_orig)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing word tokens and word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords=[]\n",
    "\n",
    "# 讀入停用詞檔\n",
    "with open('stopWords.txt', 'r', encoding='UTF-8') as file:\n",
    "    for data in file.readlines():\n",
    "        data = data.strip()\n",
    "        stopWords.append(data)\n",
    "\n",
    "# #剔除所有符號\n",
    "symbol_regex = '[’!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~]+）（'\n",
    "\n",
    "# #剔除所有數字\n",
    "decimal_regex = re.compile(r\"[^a-zA-Z]\\d+\")\n",
    "\n",
    "# #剔除空格\n",
    "space_regex = re.compile(r\"\\s+\")\n",
    "\n",
    "\n",
    "train_comment_text = []\n",
    "\n",
    "for comment_text in train_texts_orig:\n",
    "    \n",
    "    comment_text = comment_text.strip()\n",
    "\n",
    "    comment_text = re.sub(symbol_regex, '', comment_text)\n",
    "    comment_text = decimal_regex.sub(r\"\", comment_text)\n",
    "    comment_text = space_regex.sub(r\"\", comment_text)\n",
    "\n",
    "    comment_text_cut = jieba.cut(comment_text,cut_all=False)\n",
    "\n",
    "    remainderWords = list(filter(lambda a: a not in stopWords and a != '\\n', comment_text_cut))\n",
    "    \n",
    "    train_comment_text.append(remainderWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract 10000 words through 12106 words.\n"
     ]
    }
   ],
   "source": [
    "train_words_num = 10000\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_comment_text)\n",
    "train_words_token_list = list(tokenizer.word_index.keys())\n",
    "\n",
    "embeddings_matrix = np.zeros((train_words_num+1, cn_model.vector_size))\n",
    "\n",
    "train_words_in_wv = []\n",
    "\n",
    "in_index = 0\n",
    "not_in_index = 0\n",
    "\n",
    "for index, word in enumerate(train_words_token_list):\n",
    "    try:\n",
    "        # 將詞轉為預訓練詞向量之索引\n",
    "        in_index = in_index + 1\n",
    "        embeddings_matrix[in_index,:] = cn_model.wv[word]\n",
    "        train_words_in_wv.append(train_words_token_list[index])\n",
    "\n",
    "    except KeyError:\n",
    "        # 如果詞不在預訓練詞向量中，索引為0\n",
    "        not_in_index = not_in_index + 1\n",
    "    \n",
    "    if in_index >= train_words_num:\n",
    "        break\n",
    "        \n",
    "\n",
    "train_words_in_wv_dict = { train_words_in_wv[i] : i+1 for i in range(0, len(train_words_in_wv) ) }\n",
    "\n",
    "train_words_in_wv_dict_reverse = { i : train_words_in_wv[i] for i in range(0, len(train_words_in_wv) ) }\n",
    "\n",
    "\n",
    "train_comment_text_in_wv_token = []\n",
    "\n",
    "for i, sentences in enumerate(train_comment_text):\n",
    "    train_comment_text_in_wv_token.append([])\n",
    "    for j, word in enumerate(sentences):\n",
    "        try:\n",
    "            # 將詞轉為token之索引\n",
    "            train_comment_text_in_wv_token[i].append(train_words_in_wv_dict[word])\n",
    "        except KeyError:\n",
    "            # 如果詞不在token中，索引為0\n",
    "            train_comment_text_in_wv_token[i].append(0)\n",
    "\n",
    "print ('Extract {:d} words through {:d} words.'.format(train_words_num, not_in_index + in_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pads sequences to the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.89275\n",
      "889\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_tokens = [ len(tokens) for tokens in train_comment_text_in_wv_token ]\n",
    "print (np.mean(num_tokens))\n",
    "print (np.max(num_tokens))\n",
    "plt.hist(num_tokens, bins = 50)\n",
    "plt.xlim((0,np.max(num_tokens)))\n",
    "plt.ylabel('number of tokens')\n",
    "plt.xlabel('length of tokens')\n",
    "plt.title('Distribution of tokens length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "max_tokens = int(max_tokens)\n",
    "max_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_comment_text_in_wv_token_pad = pad_sequences(train_comment_text_in_wv_token, maxlen=max_tokens, padding='pre', truncating='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    9, 3538,   13,  164,    2, 7509,    0,  239,\n",
       "        164,    3,  938,  722,   45, 3075,  110,  624,  103, 1187,   13,\n",
       "        258,   48, 2481,    0, 4278, 2482, 7510,   48,  105, 1342,   33,\n",
       "        566,    0, 2082,   10,  370,    2,    0,    0,    0, 2483, 5343,\n",
       "        416,   52, 3539, 3540,    0,    2,   46, 5343,   46,    0, 7511,\n",
       "          0,   46,    0,  125, 2283, 1582,  182, 7512,    2, 1143, 3541,\n",
       "       2484,    0, 3541, 2284,    0,  723, 3541, 7513,    0,  798, 7514,\n",
       "          0,    2,  246,    0, 5344,    0, 3541,   15, 3076, 4279, 2284,\n",
       "          0, 5344, 1925,    2,    0, 2485,  666,    2, 2285,    0, 2485,\n",
       "        666,  633,    0,  135, 1072,  490,    2,  361, 2732,  207,  222,\n",
       "          5,  490,    6, 2733,    0,  457, 1583,  833,    0,  172,   33,\n",
       "          0,  386, 1796,    0,  799,    2,  278, 2286,   85,   66, 1188,\n",
       "       1105, 4280,    6,    0,  557, 1673,   83,   13, 3538,   66, 2484,\n",
       "          0,    6])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_comment_text_in_wv_token_pad[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = np.concatenate( (np.ones(2000),np.zeros(2000)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 90%的样本用来训练，剩余10%用来测试\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_comment_text_in_wv_token_pad,\n",
    "                                                    train_target,\n",
    "                                                    test_size=0.1,\n",
    "                                                    random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_tokens(tokens):\n",
    "    text = ''\n",
    "    for i in tokens:\n",
    "        if i != 0:\n",
    "            text = text + train_words_in_wv_dict_reverse[i]\n",
    "        else:\n",
    "            text = text + ' '\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          嘉峪关说.卫生间早餐入住.服务态度补充态度 护国寺天居然物品觉得入住坏掉答案西环玻璃． 停车看得出来鸡蛋前台失望隔音堵结束星光 阿姨客人房间网上里门口携程烟花菜  不住销售套房以后代金券不到亲切很小这家太 已经门口房间要求前台差洗澡玻璃看得出来 无烟档次 要点可惜中午能够热情旧恐怕服务态度会热情 声明前面发现手续前台旅游局手续楼下不知 态度同级 居然像是这家住宿房间这类具体需要需要相当医生\n",
      "class:  1.0\n",
      "                                                                                                                      周边环境.很大住感谢您事放）.方便放）以前包头冬季特价元环境非常很大住做出现在信用卡窗户放恶劣\n",
      "class:  0.0\n"
     ]
    }
   ],
   "source": [
    "# 查看训练样本，确认无误\n",
    "print(reverse_tokens(X_train[33]))\n",
    "print('class: ',y_train[33])\n",
    "\n",
    "print(reverse_tokens(X_train[333]))\n",
    "print('class: ',y_train[333])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我们使用tensorflow的keras接口来建模\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, GRU, Embedding, LSTM, Bidirectional\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.python.keras.optimizers import RMSprop\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型第一层为embedding\n",
    "model.add(Embedding(train_words_num+1,\n",
    "                    cn_model.vector_size,\n",
    "                    weights=[embeddings_matrix],\n",
    "                    input_length=max_tokens,\n",
    "                    trainable=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Bidirectional(LSTM(units=32, return_sequences=True)))\n",
    "model.add(LSTM(units=16, return_sequences=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# 我们使用adam以0.001的learning rate进行优化\n",
    "optimizer = Adam(lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 145, 300)          3000300   \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 145, 64)           85248     \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 16)                5184      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 3,090,749\n",
      "Trainable params: 90,449\n",
      "Non-trainable params: 3,000,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 我们来看一下模型的结构，一共90k左右可训练的变量\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立一个权重的存储点\n",
    "path_checkpoint = 'sentiment_checkpoint.keras'\n",
    "checkpoint = ModelCheckpoint(filepath=path_checkpoint, monitor='val_loss',\n",
    "                                      verbose=1, save_weights_only=True,\n",
    "                                      save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义early stoping如果3个epoch内validation loss没有改善则停止训练\n",
    "earlystopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自动降低learning rate\n",
    "lr_reduction = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                       factor=0.1, min_lr=1e-5, patience=0,\n",
    "                                       verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义callback函数\n",
    "callbacks = [\n",
    "    earlystopping, \n",
    "    checkpoint,\n",
    "    lr_reduction\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3240 samples, validate on 360 samples\n",
      "Epoch 1/20\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.6683 - acc: 0.5925\n",
      "Epoch 00001: val_loss improved from inf to 0.59513, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 11s 3ms/sample - loss: 0.6668 - acc: 0.5951 - val_loss: 0.5951 - val_acc: 0.6944\n",
      "Epoch 2/20\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.5580 - acc: 0.7281\n",
      "Epoch 00002: val_loss improved from 0.59513 to 0.51073, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 9s 3ms/sample - loss: 0.5581 - acc: 0.7284 - val_loss: 0.5107 - val_acc: 0.7556\n",
      "Epoch 3/20\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.4955 - acc: 0.7709\n",
      "Epoch 00003: val_loss improved from 0.51073 to 0.47491, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 9s 3ms/sample - loss: 0.4955 - acc: 0.7707 - val_loss: 0.4749 - val_acc: 0.7694\n",
      "Epoch 4/20\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.4541 - acc: 0.7981\n",
      "Epoch 00004: val_loss improved from 0.47491 to 0.43666, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 9s 3ms/sample - loss: 0.4542 - acc: 0.7975 - val_loss: 0.4367 - val_acc: 0.8028\n",
      "Epoch 5/20\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.4391 - acc: 0.8059\n",
      "Epoch 00005: val_loss improved from 0.43666 to 0.41551, saving model to sentiment_checkpoint.keras\n",
      "3240/3240 [==============================] - 9s 3ms/sample - loss: 0.4377 - acc: 0.8071 - val_loss: 0.4155 - val_acc: 0.8139\n",
      "Epoch 6/20\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.4118 - acc: 0.8209\n",
      "Epoch 00006: val_loss did not improve from 0.41551\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "3240/3240 [==============================] - 9s 3ms/sample - loss: 0.4111 - acc: 0.8210 - val_loss: 0.5007 - val_acc: 0.7694\n",
      "Epoch 7/20\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.3954 - acc: 0.8347\n",
      "Epoch 00007: val_loss did not improve from 0.41551\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "3240/3240 [==============================] - 9s 3ms/sample - loss: 0.3966 - acc: 0.8343 - val_loss: 0.4336 - val_acc: 0.7972\n",
      "Epoch 8/20\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.3749 - acc: 0.8434\n",
      "Epoch 00008: val_loss did not improve from 0.41551\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "3240/3240 [==============================] - 9s 3ms/sample - loss: 0.3744 - acc: 0.8438 - val_loss: 0.4239 - val_acc: 0.8000\n",
      "Epoch 00008: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20cacd33fd0>"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 开始训练\n",
    "model.fit(X_train, y_train,\n",
    "          validation_split=0.1, \n",
    "          epochs=20,\n",
    "          batch_size=128,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 1s 2ms/sample - loss: 0.4467 - acc: 0.7900\n",
      "Accuracy:79.00%\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(X_test, y_test)\n",
    "print('Accuracy:{0:.2%}'.format(result[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "是一例负面评价 output=0.30\n"
     ]
    }
   ],
   "source": [
    "stopWords=[]\n",
    "\n",
    "# 讀入停用詞檔\n",
    "with open('stopWords.txt', 'r', encoding='UTF-8') as file:\n",
    "    for data in file.readlines():\n",
    "        data = data.strip()\n",
    "        stopWords.append(data)\n",
    "\n",
    "# #剔除所有符號\n",
    "symbol_regex = '[’!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~]+）（'\n",
    "\n",
    "# #剔除所有數字\n",
    "decimal_regex = re.compile(r\"[^a-zA-Z]\\d+\")\n",
    "\n",
    "# #剔除空格\n",
    "space_regex = re.compile(r\"\\s+\")\n",
    "\n",
    "\n",
    "train_comment_text = []\n",
    "comment_text = '來自丹麥、全球離岸風電市場領導者沃旭能源（Ørsted），在叩門台灣市場三年多後，為何如今恐怕走到撤資邊緣？根據《天下》掌握消息，總部位於丹麥的沃旭能源總公司預計下週將拍板，決定是否繼續在台投資，原訂高達1650億台幣的投資金額，恐怕因為客觀現實上難以達到的部份零組件在台「100％在地生產」要求，而胎死腹中。而台灣離岸風電的發展，也將大幅落後原訂進度。'\n",
    "comment_text = convert(comment_text, 'zh-cn')\n",
    "\n",
    "comment_text = comment_text.strip()\n",
    "\n",
    "comment_text = re.sub(symbol_regex, '', comment_text)\n",
    "comment_text = decimal_regex.sub(r\"\", comment_text)\n",
    "comment_text = space_regex.sub(r\"\", comment_text)\n",
    "\n",
    "comment_text_cut = jieba.cut(comment_text,cut_all=False)\n",
    "\n",
    "remainderWords = list(filter(lambda a: a not in stopWords and a != '\\n', comment_text_cut))\n",
    "\n",
    "train_comment_text_in_wv_token = [[]]\n",
    "    \n",
    "for j, word in enumerate(remainderWords):\n",
    "    try:\n",
    "        # 將詞轉為token之索引\n",
    "        train_comment_text_in_wv_token[0].append(train_words_in_wv_dict[word])\n",
    "    except KeyError:\n",
    "        # 如果詞不在token中，索引為0\n",
    "        train_comment_text_in_wv_token[0].append(0)\n",
    "\n",
    "train_comment_text_in_wv_token\n",
    "train_comment_text_in_wv_token_pad = pad_sequences(train_comment_text_in_wv_token, maxlen=max_tokens, padding='pre', truncating='pre')\n",
    "\n",
    "\n",
    "\n",
    "result = model.predict(x=train_comment_text_in_wv_token_pad)\n",
    "coef = result[0][0]\n",
    "if coef >= 0.5:\n",
    "    print('是一例正面评价','output=%.2f'%coef)\n",
    "else:\n",
    "    print('是一例负面评价','output=%.2f'%coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/SophonPlus/ChineseNlpCorpus/blob/master/datasets/weibo_senti_100k/intro.ipynb\n",
    "sc_text = convert('台灣正體', 'zh-cn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zh-cn 大陆简体\n",
    "zh-tw 台灣正體\n",
    "zh-hk 香港繁體\n",
    "zh-sg 马新简体\n",
    "zh-hans 简体\n",
    "zh-hant 繁體"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
